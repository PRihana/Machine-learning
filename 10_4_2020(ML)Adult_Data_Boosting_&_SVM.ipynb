{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-4-2020(ML)Adult Data Boosting & SVM.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOQbg7AA+3SXljPYCPvk+6E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRihana/Machine-learning/blob/master/10_4_2020(ML)Adult_Data_Boosting_%26_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLcPhb9htLuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "70cbb1d6-1c58-4987-e94a-cc540448a04e"
      },
      "source": [
        "import pandas as pd\n",
        "data =pd.read_csv(\"/content/adult.data.txt\",names = [\"age\",\"workclass\",\"fnlwgt\",\"education\",\"education_num\",\\\n",
        "            'marital_status',\"occupation\",\"relationship\",\"race\",\"Gender\",\"capital-gain\",\"capital-loss\",\"hours-per-week\",\\\n",
        "                                             \"native-country\",\"income\"])\n",
        "\n",
        "data.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education_num</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>Gender</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>State-gov</td>\n",
              "      <td>77516</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>83311</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>Private</td>\n",
              "      <td>215646</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>Private</td>\n",
              "      <td>234721</td>\n",
              "      <td>11th</td>\n",
              "      <td>7</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Handlers-cleaners</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>338409</td>\n",
              "      <td>Bachelors</td>\n",
              "      <td>13</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Wife</td>\n",
              "      <td>Black</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Cuba</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age          workclass  fnlwgt  ... hours-per-week  native-country  income\n",
              "0   39          State-gov   77516  ...             40   United-States   <=50K\n",
              "1   50   Self-emp-not-inc   83311  ...             13   United-States   <=50K\n",
              "2   38            Private  215646  ...             40   United-States   <=50K\n",
              "3   53            Private  234721  ...             40   United-States   <=50K\n",
              "4   28            Private  338409  ...             40            Cuba   <=50K\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXkU8o1cx8zd",
        "colab_type": "text"
      },
      "source": [
        "50K, <=50K. age: continuous. workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked. fnlwgt: continuous. education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool. education-num: continuous. marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse. occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces. relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried. race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black. sex: Female, Male. capital-gain: continuous. capital-loss: continuous. hours-per-week: continuous. native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTZOjG_ovZhR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a7411ec9-91df-4af0-9618-6514fac64f7d"
      },
      "source": [
        "data.income.value_counts()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " <=50K    24720\n",
              " >50K      7841\n",
              "Name: income, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR1KxDZRvZxR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "21d549a6-14a8-413a-e69a-db888ccc88e0"
      },
      "source": [
        "data.income.value_counts(normalize=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " <=50K    0.75919\n",
              " >50K     0.24081\n",
              "Name: income, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfjEP53FvZv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "91aee6d8-8a90-4932-c8b5-1f83de33e472"
      },
      "source": [
        "data.isna().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age               0\n",
              "workclass         0\n",
              "fnlwgt            0\n",
              "education         0\n",
              "education_num     0\n",
              "marital_status    0\n",
              "occupation        0\n",
              "relationship      0\n",
              "race              0\n",
              "Gender            0\n",
              "capital-gain      0\n",
              "capital-loss      0\n",
              "hours-per-week    0\n",
              "native-country    0\n",
              "income            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMw3TeI5vZui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f299f827-0c55-4336-811b-ee27a460f5b4"
      },
      "source": [
        "data.corr()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.076646</td>\n",
              "      <td>0.036527</td>\n",
              "      <td>0.077674</td>\n",
              "      <td>0.057775</td>\n",
              "      <td>0.068756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fnlwgt</th>\n",
              "      <td>-0.076646</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.043195</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>-0.010252</td>\n",
              "      <td>-0.018768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>education_num</th>\n",
              "      <td>0.036527</td>\n",
              "      <td>-0.043195</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.122630</td>\n",
              "      <td>0.079923</td>\n",
              "      <td>0.148123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-gain</th>\n",
              "      <td>0.077674</td>\n",
              "      <td>0.000432</td>\n",
              "      <td>0.122630</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.031615</td>\n",
              "      <td>0.078409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capital-loss</th>\n",
              "      <td>0.057775</td>\n",
              "      <td>-0.010252</td>\n",
              "      <td>0.079923</td>\n",
              "      <td>-0.031615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.054256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hours-per-week</th>\n",
              "      <td>0.068756</td>\n",
              "      <td>-0.018768</td>\n",
              "      <td>0.148123</td>\n",
              "      <td>0.078409</td>\n",
              "      <td>0.054256</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     age    fnlwgt  ...  capital-loss  hours-per-week\n",
              "age             1.000000 -0.076646  ...      0.057775        0.068756\n",
              "fnlwgt         -0.076646  1.000000  ...     -0.010252       -0.018768\n",
              "education_num   0.036527 -0.043195  ...      0.079923        0.148123\n",
              "capital-gain    0.077674  0.000432  ...     -0.031615        0.078409\n",
              "capital-loss    0.057775 -0.010252  ...      1.000000        0.054256\n",
              "hours-per-week  0.068756 -0.018768  ...      0.054256        1.000000\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDtmj_VVvZss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "e18c90b0-115f-465e-9f98-ef420212d517"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>32561.000000</td>\n",
              "      <td>3.256100e+04</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "      <td>32561.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>38.581647</td>\n",
              "      <td>1.897784e+05</td>\n",
              "      <td>10.080679</td>\n",
              "      <td>1077.648844</td>\n",
              "      <td>87.303830</td>\n",
              "      <td>40.437456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>13.640433</td>\n",
              "      <td>1.055500e+05</td>\n",
              "      <td>2.572720</td>\n",
              "      <td>7385.292085</td>\n",
              "      <td>402.960219</td>\n",
              "      <td>12.347429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.228500e+04</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.178270e+05</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>37.000000</td>\n",
              "      <td>1.783560e+05</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.370510e+05</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>90.000000</td>\n",
              "      <td>1.484705e+06</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>99999.000000</td>\n",
              "      <td>4356.000000</td>\n",
              "      <td>99.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                age        fnlwgt  ...  capital-loss  hours-per-week\n",
              "count  32561.000000  3.256100e+04  ...  32561.000000    32561.000000\n",
              "mean      38.581647  1.897784e+05  ...     87.303830       40.437456\n",
              "std       13.640433  1.055500e+05  ...    402.960219       12.347429\n",
              "min       17.000000  1.228500e+04  ...      0.000000        1.000000\n",
              "25%       28.000000  1.178270e+05  ...      0.000000       40.000000\n",
              "50%       37.000000  1.783560e+05  ...      0.000000       40.000000\n",
              "75%       48.000000  2.370510e+05  ...      0.000000       45.000000\n",
              "max       90.000000  1.484705e+06  ...   4356.000000       99.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jg9G-JGdvZqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "fc916343-7ef9-4adb-f46e-f9f67effec9b"
      },
      "source": [
        "%matplotlib inline\n",
        "data[\"capital-gain\"].hist()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f19c9b06a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1xxdV1mvZnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "772bba6d-cad3-474c-9eb8-03c5a4d2cf0b"
      },
      "source": [
        "import numpy as np\n",
        "np.log1p(data[\"capital-gain\"]).hist()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f19c9a49390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Kt1vR2vZkX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fced474a-8589-43db-a4a4-f1005c679326"
      },
      "source": [
        "(data['capital-gain']==0).sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgBv6CVVyo8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "dafd23a9-b5e1-4e47-fc63-7a579f4a3a97"
      },
      "source": [
        "data.select_dtypes(exclude=object)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education_num</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>39</td>\n",
              "      <td>77516</td>\n",
              "      <td>13</td>\n",
              "      <td>2174</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>50</td>\n",
              "      <td>83311</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>38</td>\n",
              "      <td>215646</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>53</td>\n",
              "      <td>234721</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>28</td>\n",
              "      <td>338409</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32556</th>\n",
              "      <td>27</td>\n",
              "      <td>257302</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32557</th>\n",
              "      <td>40</td>\n",
              "      <td>154374</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32558</th>\n",
              "      <td>58</td>\n",
              "      <td>151910</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32559</th>\n",
              "      <td>22</td>\n",
              "      <td>201490</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32560</th>\n",
              "      <td>52</td>\n",
              "      <td>287927</td>\n",
              "      <td>9</td>\n",
              "      <td>15024</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32561 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  fnlwgt  education_num  capital-gain  capital-loss  hours-per-week\n",
              "0       39   77516             13          2174             0              40\n",
              "1       50   83311             13             0             0              13\n",
              "2       38  215646              9             0             0              40\n",
              "3       53  234721              7             0             0              40\n",
              "4       28  338409             13             0             0              40\n",
              "...    ...     ...            ...           ...           ...             ...\n",
              "32556   27  257302             12             0             0              38\n",
              "32557   40  154374              9             0             0              40\n",
              "32558   58  151910              9             0             0              40\n",
              "32559   22  201490              9             0             0              20\n",
              "32560   52  287927              9         15024             0              40\n",
              "\n",
              "[32561 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoQz3tn7ypEo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8cb41744-105c-4582-92f0-852479068534"
      },
      "source": [
        "help(data.select_dtypes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on method select_dtypes in module pandas.core.frame:\n",
            "\n",
            "select_dtypes(include=None, exclude=None) -> 'DataFrame' method of pandas.core.frame.DataFrame instance\n",
            "    Return a subset of the DataFrame's columns based on the column dtypes.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    include, exclude : scalar or list-like\n",
            "        A selection of dtypes or strings to be included/excluded. At least\n",
            "        one of these parameters must be supplied.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    DataFrame\n",
            "        The subset of the frame including the dtypes in ``include`` and\n",
            "        excluding the dtypes in ``exclude``.\n",
            "    \n",
            "    Raises\n",
            "    ------\n",
            "    ValueError\n",
            "        * If both of ``include`` and ``exclude`` are empty\n",
            "        * If ``include`` and ``exclude`` have overlapping elements\n",
            "        * If any kind of string dtype is passed in.\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    * To select all *numeric* types, use ``np.number`` or ``'number'``\n",
            "    * To select strings you must use the ``object`` dtype, but note that\n",
            "      this will return *all* object dtype columns\n",
            "    * See the `numpy dtype hierarchy\n",
            "      <http://docs.scipy.org/doc/numpy/reference/arrays.scalars.html>`__\n",
            "    * To select datetimes, use ``np.datetime64``, ``'datetime'`` or\n",
            "      ``'datetime64'``\n",
            "    * To select timedeltas, use ``np.timedelta64``, ``'timedelta'`` or\n",
            "      ``'timedelta64'``\n",
            "    * To select Pandas categorical dtypes, use ``'category'``\n",
            "    * To select Pandas datetimetz dtypes, use ``'datetimetz'`` (new in\n",
            "      0.20.0) or ``'datetime64[ns, tz]'``\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> df = pd.DataFrame({'a': [1, 2] * 3,\n",
            "    ...                    'b': [True, False] * 3,\n",
            "    ...                    'c': [1.0, 2.0] * 3})\n",
            "    >>> df\n",
            "            a      b  c\n",
            "    0       1   True  1.0\n",
            "    1       2  False  2.0\n",
            "    2       1   True  1.0\n",
            "    3       2  False  2.0\n",
            "    4       1   True  1.0\n",
            "    5       2  False  2.0\n",
            "    \n",
            "    >>> df.select_dtypes(include='bool')\n",
            "       b\n",
            "    0  True\n",
            "    1  False\n",
            "    2  True\n",
            "    3  False\n",
            "    4  True\n",
            "    5  False\n",
            "    \n",
            "    >>> df.select_dtypes(include=['float64'])\n",
            "       c\n",
            "    0  1.0\n",
            "    1  2.0\n",
            "    2  1.0\n",
            "    3  2.0\n",
            "    4  1.0\n",
            "    5  2.0\n",
            "    \n",
            "    >>> df.select_dtypes(exclude=['int'])\n",
            "           b    c\n",
            "    0   True  1.0\n",
            "    1  False  2.0\n",
            "    2   True  1.0\n",
            "    3  False  2.0\n",
            "    4   True  1.0\n",
            "    5  False  2.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibKx0Ht6ypL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_data = data.select_dtypes(exclude=object)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6BE-phypA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "e3dd8899-4fad-4c3b-de00-49330c1b7cf7"
      },
      "source": [
        "data.income"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         <=50K\n",
              "1         <=50K\n",
              "2         <=50K\n",
              "3         <=50K\n",
              "4         <=50K\n",
              "          ...  \n",
              "32556     <=50K\n",
              "32557      >50K\n",
              "32558     <=50K\n",
              "32559     <=50K\n",
              "32560      >50K\n",
              "Name: income, Length: 32561, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zRGGBogvZeo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "be782a4b-d393-4bb5-fc95-c59526d7fd0a"
      },
      "source": [
        "data.income[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' <=50K'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP8xO8xdzIN8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fcff8d6f-eb0d-4284-be37-4bae7e0017d1"
      },
      "source": [
        "data.income[32560]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' >50K'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHMBwWXvzIZZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "5f194987-154d-486d-b3e3-d3b531b678ee"
      },
      "source": [
        "y_apply = data.income.apply(lambda x:1 if x==' >50K' else 0)\n",
        "y_apply"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        0\n",
              "2        0\n",
              "3        0\n",
              "4        0\n",
              "        ..\n",
              "32556    0\n",
              "32557    1\n",
              "32558    0\n",
              "32559    0\n",
              "32560    1\n",
              "Name: income, Length: 32561, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHnfbDpkzIWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb0d76ff-7be8-47cf-fc09-6af89f823445"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(data.income)\n",
        "y"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKpF3TfAzZwj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = numerical_data.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOpns6wNzaAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=56)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AandtYhzZ96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "343018a7-bba6-4561-b2cb-9cbe0b26b06f"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "LS = LinearSVC()\n",
        "LS.fit(x_train,y_train)\n",
        "y_pred = LS.predict(x_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CvkfzGizITS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d43f75e8-dae2-4a1a-a177-b1f42c8f3b9f"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26806833114323253"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H718kF2Jzuvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1de2291b-76af-4d1e-e84e-b2fc566c73d6"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "LS = SVC(kernel=\"rbf\")\n",
        "LS.fit(x_train,y_train)\n",
        "y_pred = LS.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25985663082437277"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHRzzpXlzu-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "394da15b-b912-4272-d374-96756ff79028"
      },
      "source": [
        "x.dtypes"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age               int64\n",
              "fnlwgt            int64\n",
              "education_num     int64\n",
              "capital-gain      int64\n",
              "capital-loss      int64\n",
              "hours-per-week    int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_g0WD8mzvDY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "974bcdb0-8f8d-42f9-b1bf-a96461bf8afd"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "GB = GaussianNB()\n",
        "GB.fit(x_train,y_train)\n",
        "y_pred = GB.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4170482564283199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly1XH6Aezu8r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5889a76d-3ddc-4673-a778-fc48265e99fa"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "GB = GaussianNB()\n",
        "GB.fit(x_train,y_train)\n",
        "y_pred = GB.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4170482564283199"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HyiybH40AjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "25fad3ac-64c1-4b5f-c20c-9bab46d1c8ae"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "GB = BernoulliNB()\n",
        "GB.fit(x_train,y_train)\n",
        "y_pred = GB.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.31631863882443934"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNImRgj0A1p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "109222aa-adf8-4021-9a11-6eb73b567d59"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ABC = AdaBoostClassifier()\n",
        "ABC.fit(x_train,y_train)\n",
        "y_pred = ABC.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5641357027463652"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHylxCcW0Awz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22bdde11-b017-46b4-864c-3dee8b37eb2b"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=5))\n",
        "ABC.fit(x_train,y_train)\n",
        "y_pred = ABC.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5598086124401914"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psE_Ccaw0oKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d5829c9e-686b-4c5d-bb36-aab5d71e0a22"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ABC = GradientBoostingClassifier()\n",
        "ABC.fit(x_train,y_train)\n",
        "y_pred = ABC.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5696533682145193"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VDoocCG0om3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "12c13e2e-eac1-419c-fb2c-d23e11a862a3"
      },
      "source": [
        "help(GradientBoostingClassifier)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class GradientBoostingClassifier in module sklearn.ensemble._gb:\n",
            "\n",
            "class GradientBoostingClassifier(sklearn.base.ClassifierMixin, BaseGradientBoosting)\n",
            " |  Gradient Boosting for classification.\n",
            " |  \n",
            " |  GB builds an additive model in a\n",
            " |  forward stage-wise fashion; it allows for the optimization of\n",
            " |  arbitrary differentiable loss functions. In each stage ``n_classes_``\n",
            " |  regression trees are fit on the negative gradient of the\n",
            " |  binomial or multinomial deviance loss function. Binary classification\n",
            " |  is a special case where only a single regression tree is induced.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <gradient_boosting>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  loss : {'deviance', 'exponential'}, optional (default='deviance')\n",
            " |      loss function to be optimized. 'deviance' refers to\n",
            " |      deviance (= logistic regression) for classification\n",
            " |      with probabilistic outputs. For loss 'exponential' gradient\n",
            " |      boosting recovers the AdaBoost algorithm.\n",
            " |  \n",
            " |  learning_rate : float, optional (default=0.1)\n",
            " |      learning rate shrinks the contribution of each tree by `learning_rate`.\n",
            " |      There is a trade-off between learning_rate and n_estimators.\n",
            " |  \n",
            " |  n_estimators : int (default=100)\n",
            " |      The number of boosting stages to perform. Gradient boosting\n",
            " |      is fairly robust to over-fitting so a large number usually\n",
            " |      results in better performance.\n",
            " |  \n",
            " |  subsample : float, optional (default=1.0)\n",
            " |      The fraction of samples to be used for fitting the individual base\n",
            " |      learners. If smaller than 1.0 this results in Stochastic Gradient\n",
            " |      Boosting. `subsample` interacts with the parameter `n_estimators`.\n",
            " |      Choosing `subsample < 1.0` leads to a reduction of variance\n",
            " |      and an increase in bias.\n",
            " |  \n",
            " |  criterion : string, optional (default=\"friedman_mse\")\n",
            " |      The function to measure the quality of a split. Supported criteria\n",
            " |      are \"friedman_mse\" for the mean squared error with improvement\n",
            " |      score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n",
            " |      the mean absolute error. The default value of \"friedman_mse\" is\n",
            " |      generally the best as it can provide a better approximation in\n",
            " |      some cases.\n",
            " |  \n",
            " |      .. versionadded:: 0.18\n",
            " |  \n",
            " |  min_samples_split : int, float, optional (default=2)\n",
            " |      The minimum number of samples required to split an internal node:\n",
            " |  \n",
            " |      - If int, then consider `min_samples_split` as the minimum number.\n",
            " |      - If float, then `min_samples_split` is a fraction and\n",
            " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
            " |        number of samples for each split.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_samples_leaf : int, float, optional (default=1)\n",
            " |      The minimum number of samples required to be at a leaf node.\n",
            " |      A split point at any depth will only be considered if it leaves at\n",
            " |      least ``min_samples_leaf`` training samples in each of the left and\n",
            " |      right branches.  This may have the effect of smoothing the model,\n",
            " |      especially in regression.\n",
            " |  \n",
            " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
            " |      - If float, then `min_samples_leaf` is a fraction and\n",
            " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
            " |        number of samples for each node.\n",
            " |  \n",
            " |      .. versionchanged:: 0.18\n",
            " |         Added float values for fractions.\n",
            " |  \n",
            " |  min_weight_fraction_leaf : float, optional (default=0.)\n",
            " |      The minimum weighted fraction of the sum total of weights (of all\n",
            " |      the input samples) required to be at a leaf node. Samples have\n",
            " |      equal weight when sample_weight is not provided.\n",
            " |  \n",
            " |  max_depth : integer, optional (default=3)\n",
            " |      maximum depth of the individual regression estimators. The maximum\n",
            " |      depth limits the number of nodes in the tree. Tune this parameter\n",
            " |      for best performance; the best value depends on the interaction\n",
            " |      of the input variables.\n",
            " |  \n",
            " |  min_impurity_decrease : float, optional (default=0.)\n",
            " |      A node will be split if this split induces a decrease of the impurity\n",
            " |      greater than or equal to this value.\n",
            " |  \n",
            " |      The weighted impurity decrease equation is the following::\n",
            " |  \n",
            " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
            " |                              - N_t_L / N_t * left_impurity)\n",
            " |  \n",
            " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
            " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
            " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
            " |  \n",
            " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
            " |      if ``sample_weight`` is passed.\n",
            " |  \n",
            " |      .. versionadded:: 0.19\n",
            " |  \n",
            " |  min_impurity_split : float, (default=1e-7)\n",
            " |      Threshold for early stopping in tree growth. A node will split\n",
            " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
            " |  \n",
            " |      .. deprecated:: 0.19\n",
            " |         ``min_impurity_split`` has been deprecated in favor of\n",
            " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
            " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
            " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
            " |  \n",
            " |  init : estimator or 'zero', optional (default=None)\n",
            " |      An estimator object that is used to compute the initial predictions.\n",
            " |      ``init`` has to provide :meth:`fit` and :meth:`predict_proba`. If\n",
            " |      'zero', the initial raw predictions are set to zero. By default, a\n",
            " |      ``DummyEstimator`` predicting the classes priors is used.\n",
            " |  \n",
            " |  random_state : int, RandomState instance or None, optional (default=None)\n",
            " |      If int, random_state is the seed used by the random number generator;\n",
            " |      If RandomState instance, random_state is the random number generator;\n",
            " |      If None, the random number generator is the RandomState instance used\n",
            " |      by `np.random`.\n",
            " |  \n",
            " |  max_features : int, float, string or None, optional (default=None)\n",
            " |      The number of features to consider when looking for the best split:\n",
            " |  \n",
            " |      - If int, then consider `max_features` features at each split.\n",
            " |      - If float, then `max_features` is a fraction and\n",
            " |        `int(max_features * n_features)` features are considered at each\n",
            " |        split.\n",
            " |      - If \"auto\", then `max_features=sqrt(n_features)`.\n",
            " |      - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
            " |      - If \"log2\", then `max_features=log2(n_features)`.\n",
            " |      - If None, then `max_features=n_features`.\n",
            " |  \n",
            " |      Choosing `max_features < n_features` leads to a reduction of variance\n",
            " |      and an increase in bias.\n",
            " |  \n",
            " |      Note: the search for a split does not stop until at least one\n",
            " |      valid partition of the node samples is found, even if it requires to\n",
            " |      effectively inspect more than ``max_features`` features.\n",
            " |  \n",
            " |  verbose : int, default: 0\n",
            " |      Enable verbose output. If 1 then it prints progress and performance\n",
            " |      once in a while (the more trees the lower the frequency). If greater\n",
            " |      than 1 then it prints progress and performance for every tree.\n",
            " |  \n",
            " |  max_leaf_nodes : int or None, optional (default=None)\n",
            " |      Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
            " |      Best nodes are defined as relative reduction in impurity.\n",
            " |      If None then unlimited number of leaf nodes.\n",
            " |  \n",
            " |  warm_start : bool, default: False\n",
            " |      When set to ``True``, reuse the solution of the previous call to fit\n",
            " |      and add more estimators to the ensemble, otherwise, just erase the\n",
            " |      previous solution. See :term:`the Glossary <warm_start>`.\n",
            " |  \n",
            " |  presort : deprecated, default='deprecated'\n",
            " |      This parameter is deprecated and will be removed in v0.24.\n",
            " |  \n",
            " |      .. deprecated :: 0.22\n",
            " |  \n",
            " |  validation_fraction : float, optional, default 0.1\n",
            " |      The proportion of training data to set aside as validation set for\n",
            " |      early stopping. Must be between 0 and 1.\n",
            " |      Only used if ``n_iter_no_change`` is set to an integer.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  n_iter_no_change : int, default None\n",
            " |      ``n_iter_no_change`` is used to decide if early stopping will be used\n",
            " |      to terminate training when validation score is not improving. By\n",
            " |      default it is set to None to disable early stopping. If set to a\n",
            " |      number, it will set aside ``validation_fraction`` size of the training\n",
            " |      data as validation and terminate training when validation score is not\n",
            " |      improving in all of the previous ``n_iter_no_change`` numbers of\n",
            " |      iterations. The split is stratified.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  tol : float, optional, default 1e-4\n",
            " |      Tolerance for the early stopping. When the loss is not improving\n",
            " |      by at least tol for ``n_iter_no_change`` iterations (if set to a\n",
            " |      number), the training stops.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  ccp_alpha : non-negative float, optional (default=0.0)\n",
            " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
            " |      subtree with the largest cost complexity that is smaller than\n",
            " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
            " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
            " |  \n",
            " |      .. versionadded:: 0.22\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  n_estimators_ : int\n",
            " |      The number of estimators as selected by early stopping (if\n",
            " |      ``n_iter_no_change`` is specified). Otherwise it is set to\n",
            " |      ``n_estimators``.\n",
            " |  \n",
            " |      .. versionadded:: 0.20\n",
            " |  \n",
            " |  feature_importances_ : array, shape (n_features,)\n",
            " |      The feature importances (the higher, the more important the feature).\n",
            " |  \n",
            " |  oob_improvement_ : array, shape (n_estimators,)\n",
            " |      The improvement in loss (= deviance) on the out-of-bag samples\n",
            " |      relative to the previous iteration.\n",
            " |      ``oob_improvement_[0]`` is the improvement in\n",
            " |      loss of the first stage over the ``init`` estimator.\n",
            " |      Only available if ``subsample < 1.0``\n",
            " |  \n",
            " |  train_score_ : array, shape (n_estimators,)\n",
            " |      The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n",
            " |      model at iteration ``i`` on the in-bag sample.\n",
            " |      If ``subsample == 1`` this is the deviance on the training data.\n",
            " |  \n",
            " |  loss_ : LossFunction\n",
            " |      The concrete ``LossFunction`` object.\n",
            " |  \n",
            " |  init_ : estimator\n",
            " |      The estimator that provides the initial predictions.\n",
            " |      Set via the ``init`` argument or ``loss.init_estimator``.\n",
            " |  \n",
            " |  estimators_ : ndarray of DecisionTreeRegressor,shape (n_estimators, ``loss_.K``)\n",
            " |      The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n",
            " |      classification, otherwise n_classes.\n",
            " |  \n",
            " |  classes_ : array of shape (n_classes,)\n",
            " |      The classes labels.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The features are always randomly permuted at each split. Therefore,\n",
            " |  the best found split may vary, even with the same training data and\n",
            " |  ``max_features=n_features``, if the improvement of the criterion is\n",
            " |  identical for several splits enumerated during the search of the best\n",
            " |  split. To obtain a deterministic behaviour during fitting,\n",
            " |  ``random_state`` has to be fixed.\n",
            " |  \n",
            " |  See also\n",
            " |  --------\n",
            " |  sklearn.ensemble.HistGradientBoostingClassifier,\n",
            " |  sklearn.tree.DecisionTreeClassifier, RandomForestClassifier\n",
            " |  AdaBoostClassifier\n",
            " |  \n",
            " |  References\n",
            " |  ----------\n",
            " |  J. Friedman, Greedy Function Approximation: A Gradient Boosting\n",
            " |  Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n",
            " |  \n",
            " |  J. Friedman, Stochastic Gradient Boosting, 1999\n",
            " |  \n",
            " |  T. Hastie, R. Tibshirani and J. Friedman.\n",
            " |  Elements of Statistical Learning Ed. 2, Springer, 2009.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      GradientBoostingClassifier\n",
            " |      sklearn.base.ClassifierMixin\n",
            " |      BaseGradientBoosting\n",
            " |      sklearn.ensemble._base.BaseEnsemble\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, loss='deviance', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, presort='deprecated', validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Compute the decision function of ``X``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : array, shape (n_samples, n_classes) or (n_samples,)\n",
            " |          The decision function of the input samples, which corresponds to\n",
            " |          the raw values predicted from the trees of the ensemble . The\n",
            " |          order of the classes corresponds to that in the attribute\n",
            " |          :term:`classes_`. Regression and binary classification produce an\n",
            " |          array of shape [n_samples].\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Predict class for X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : array, shape (n_samples,)\n",
            " |          The predicted values.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Predict class log-probabilities for X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Raises\n",
            " |      ------\n",
            " |      AttributeError\n",
            " |          If the ``loss`` does not support probabilities.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : array, shape (n_samples, n_classes)\n",
            " |          The class log-probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Predict class probabilities for X.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Raises\n",
            " |      ------\n",
            " |      AttributeError\n",
            " |          If the ``loss`` does not support probabilities.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      p : array, shape (n_samples, n_classes)\n",
            " |          The class probabilities of the input samples. The order of the\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |  \n",
            " |  staged_decision_function(self, X)\n",
            " |      Compute decision function of ``X`` for each iteration.\n",
            " |      \n",
            " |      This method allows monitoring (i.e. determine error on testing set)\n",
            " |      after each stage.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : generator of array, shape (n_samples, k)\n",
            " |          The decision function of the input samples, which corresponds to\n",
            " |          the raw values predicted from the trees of the ensemble . The\n",
            " |          classes corresponds to that in the attribute :term:`classes_`.\n",
            " |          Regression and binary classification are special cases with\n",
            " |          ``k == 1``, otherwise ``k==n_classes``.\n",
            " |  \n",
            " |  staged_predict(self, X)\n",
            " |      Predict class at each stage for X.\n",
            " |      \n",
            " |      This method allows monitoring (i.e. determine error on testing set)\n",
            " |      after each stage.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : generator of array of shape (n_samples,)\n",
            " |          The predicted value of the input samples.\n",
            " |  \n",
            " |  staged_predict_proba(self, X)\n",
            " |      Predict class probabilities at each stage for X.\n",
            " |      \n",
            " |      This method allows monitoring (i.e. determine error on testing set)\n",
            " |      after each stage.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      y : generator of array of shape (n_samples,)\n",
            " |          The predicted value of the input samples.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  score(self, X, y, sample_weight=None)\n",
            " |      Return the mean accuracy on the given test data and labels.\n",
            " |      \n",
            " |      In multi-label classification, this is the subset accuracy\n",
            " |      which is a harsh metric since you require for each sample that\n",
            " |      each label set be correctly predicted.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Test samples.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
            " |          True labels for X.\n",
            " |      \n",
            " |      sample_weight : array-like of shape (n_samples,), default=None\n",
            " |          Sample weights.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |          Mean accuracy of self.predict(X) wrt. y.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseGradientBoosting:\n",
            " |  \n",
            " |  apply(self, X)\n",
            " |      Apply trees in the ensemble to X, return leaf indices.\n",
            " |      \n",
            " |      .. versionadded:: 0.17\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, its dtype will be converted to\n",
            " |          ``dtype=np.float32``. If a sparse matrix is provided, it will\n",
            " |          be converted to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      X_leaves : array-like, shape (n_samples, n_estimators, n_classes)\n",
            " |          For each datapoint x in X and for each tree in the ensemble,\n",
            " |          return the index of the leaf x ends up in each estimator.\n",
            " |          In the case of binary classification n_classes is 1.\n",
            " |  \n",
            " |  fit(self, X, y, sample_weight=None, monitor=None)\n",
            " |      Fit the gradient boosting model.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
            " |          The input samples. Internally, it will be converted to\n",
            " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
            " |          to a sparse ``csr_matrix``.\n",
            " |      \n",
            " |      y : array-like, shape (n_samples,)\n",
            " |          Target values (strings or integers in classification, real numbers\n",
            " |          in regression)\n",
            " |          For classification, labels must correspond to classes.\n",
            " |      \n",
            " |      sample_weight : array-like, shape (n_samples,) or None\n",
            " |          Sample weights. If None, then samples are equally weighted. Splits\n",
            " |          that would create child nodes with net zero or negative weight are\n",
            " |          ignored while searching for a split in each node. In the case of\n",
            " |          classification, splits are also ignored if they would result in any\n",
            " |          single class carrying a negative weight in either child node.\n",
            " |      \n",
            " |      monitor : callable, optional\n",
            " |          The monitor is called after each iteration with the current\n",
            " |          iteration, a reference to the estimator and the local variables of\n",
            " |          ``_fit_stages`` as keyword arguments ``callable(i, self,\n",
            " |          locals())``. If the callable returns ``True`` the fitting procedure\n",
            " |          is stopped. The monitor can be used for various things such as\n",
            " |          computing held-out estimates, early stopping, model introspect, and\n",
            " |          snapshoting.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from BaseGradientBoosting:\n",
            " |  \n",
            " |  feature_importances_\n",
            " |      Return the feature importances (the higher, the more important the\n",
            " |         feature).\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      feature_importances_ : array, shape (n_features,)\n",
            " |          The values of this array sum to 1, unless all trees are single node\n",
            " |          trees consisting of only the root node, in which case it will be an\n",
            " |          array of zeros.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.ensemble._base.BaseEnsemble:\n",
            " |  \n",
            " |  __getitem__(self, index)\n",
            " |      Return the index'th estimator in the ensemble.\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |      Return iterator over estimators in the ensemble.\n",
            " |  \n",
            " |  __len__(self)\n",
            " |      Return the number of estimators in the ensemble.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Estimator instance.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1ibGYWG0olE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7e071bfd-231f-4857-9ff6-adfb1ce7f2f6"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "ABC = GradientBoostingClassifier(subsample=0.5)\n",
        "ABC.fit(x_train,y_train)\n",
        "y_pred = ABC.predict(x_test)\n",
        "f1_score(y_pred,y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5751928020565552"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j05udzER0ojf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2iL2uyN0ohy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0q59ocAH0ogJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqVvwHSF0obZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9Zj6vv0oQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}