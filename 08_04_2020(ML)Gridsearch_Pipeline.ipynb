{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08-04-2020(ML)Gridsearch-Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEwTzg9OgdZnQj3J+1RLVu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRihana/Machine-learning/blob/master/08_04_2020(ML)Gridsearch_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkwYGkWqhoOT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/bostonhousing.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctPjq52XhoWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "33d495e9-52c0-43af-e143-4e8170db74cd"
      },
      "source": [
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3</td>\n",
              "      <td>222</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>0.06263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.593</td>\n",
              "      <td>69.1</td>\n",
              "      <td>2.4786</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>391.99</td>\n",
              "      <td>9.67</td>\n",
              "      <td>22.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>0.04527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.120</td>\n",
              "      <td>76.7</td>\n",
              "      <td>2.2875</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.08</td>\n",
              "      <td>20.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>0.06076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.976</td>\n",
              "      <td>91.0</td>\n",
              "      <td>2.1675</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.64</td>\n",
              "      <td>23.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>0.10959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.794</td>\n",
              "      <td>89.3</td>\n",
              "      <td>2.3889</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>393.45</td>\n",
              "      <td>6.48</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0.573</td>\n",
              "      <td>6.030</td>\n",
              "      <td>80.8</td>\n",
              "      <td>2.5050</td>\n",
              "      <td>1</td>\n",
              "      <td>273</td>\n",
              "      <td>21.0</td>\n",
              "      <td>396.90</td>\n",
              "      <td>7.88</td>\n",
              "      <td>11.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>506 rows × 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        crim    zn  indus  chas    nox  ...  tax  ptratio       b  lstat  medv\n",
              "0    0.00632  18.0   2.31     0  0.538  ...  296     15.3  396.90   4.98  24.0\n",
              "1    0.02731   0.0   7.07     0  0.469  ...  242     17.8  396.90   9.14  21.6\n",
              "2    0.02729   0.0   7.07     0  0.469  ...  242     17.8  392.83   4.03  34.7\n",
              "3    0.03237   0.0   2.18     0  0.458  ...  222     18.7  394.63   2.94  33.4\n",
              "4    0.06905   0.0   2.18     0  0.458  ...  222     18.7  396.90   5.33  36.2\n",
              "..       ...   ...    ...   ...    ...  ...  ...      ...     ...    ...   ...\n",
              "501  0.06263   0.0  11.93     0  0.573  ...  273     21.0  391.99   9.67  22.4\n",
              "502  0.04527   0.0  11.93     0  0.573  ...  273     21.0  396.90   9.08  20.6\n",
              "503  0.06076   0.0  11.93     0  0.573  ...  273     21.0  396.90   5.64  23.9\n",
              "504  0.10959   0.0  11.93     0  0.573  ...  273     21.0  393.45   6.48  22.0\n",
              "505  0.04741   0.0  11.93     0  0.573  ...  273     21.0  396.90   7.88  11.9\n",
              "\n",
              "[506 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuVnig4ihoUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = data['medv']\n",
        "x = data.drop(\"medv\",axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP7tngoKhoRy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state=23)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaxCNke_hoMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8f746bd8-4c5d-486f-8f48-1ee5e6249415"
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>0.12329</td>\n",
              "      <td>0.0</td>\n",
              "      <td>10.01</td>\n",
              "      <td>0</td>\n",
              "      <td>0.547</td>\n",
              "      <td>5.913</td>\n",
              "      <td>92.9</td>\n",
              "      <td>2.3534</td>\n",
              "      <td>6</td>\n",
              "      <td>432</td>\n",
              "      <td>17.8</td>\n",
              "      <td>394.95</td>\n",
              "      <td>16.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>0.03537</td>\n",
              "      <td>34.0</td>\n",
              "      <td>6.09</td>\n",
              "      <td>0</td>\n",
              "      <td>0.433</td>\n",
              "      <td>6.590</td>\n",
              "      <td>40.4</td>\n",
              "      <td>5.4917</td>\n",
              "      <td>7</td>\n",
              "      <td>329</td>\n",
              "      <td>16.1</td>\n",
              "      <td>395.75</td>\n",
              "      <td>9.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>14.23620</td>\n",
              "      <td>0.0</td>\n",
              "      <td>18.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.693</td>\n",
              "      <td>6.343</td>\n",
              "      <td>100.0</td>\n",
              "      <td>1.5741</td>\n",
              "      <td>24</td>\n",
              "      <td>666</td>\n",
              "      <td>20.2</td>\n",
              "      <td>396.90</td>\n",
              "      <td>20.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>0.05425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.05</td>\n",
              "      <td>0</td>\n",
              "      <td>0.510</td>\n",
              "      <td>6.315</td>\n",
              "      <td>73.4</td>\n",
              "      <td>3.3175</td>\n",
              "      <td>5</td>\n",
              "      <td>296</td>\n",
              "      <td>16.6</td>\n",
              "      <td>395.60</td>\n",
              "      <td>6.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>0.12816</td>\n",
              "      <td>12.5</td>\n",
              "      <td>6.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.409</td>\n",
              "      <td>5.885</td>\n",
              "      <td>33.0</td>\n",
              "      <td>6.4980</td>\n",
              "      <td>4</td>\n",
              "      <td>345</td>\n",
              "      <td>18.9</td>\n",
              "      <td>396.90</td>\n",
              "      <td>8.79</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         crim    zn  indus  chas    nox  ...  rad  tax  ptratio       b  lstat\n",
              "112   0.12329   0.0  10.01     0  0.547  ...    6  432     17.8  394.95  16.21\n",
              "301   0.03537  34.0   6.09     0  0.433  ...    7  329     16.1  395.75   9.50\n",
              "401  14.23620   0.0  18.10     0  0.693  ...   24  666     20.2  396.90  20.32\n",
              "177   0.05425   0.0   4.05     0  0.510  ...    5  296     16.6  395.60   6.29\n",
              "69    0.12816  12.5   6.07     0  0.409  ...    4  345     18.9  396.90   8.79\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybaZHq8PhoLr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0232728b-3d80-443e-8fc5-5c17ce16d964"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "knr = KNeighborsRegressor(n_neighbors=4,weights=\"distance\")\n",
        "knr.fit(x_train,y_train)\n",
        "y_pred = knr.predict(x_test)\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43.11097182880768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fXenbBUhoIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3ccdd6d8-5e45-4a8b-c716-ebb1111ea885"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "knr = KNeighborsRegressor(n_neighbors=4,weights=\"uniform\")\n",
        "knr.fit(x_train,y_train)\n",
        "y_pred = knr.predict(x_test)\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44.80862204724409"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhnHaLmGhoFQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fed87c1d-0259-477f-c60f-ced8bd3429cb"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "knr = KNeighborsRegressor(n_neighbors=5)\n",
        "knr.fit(x_train,y_train)\n",
        "y_pred = knr.predict(x_test)\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.59168503937007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMIhAPiuhoCt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "53401605-bcab-4baf-c543-ed15e8bb58de"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "knr = KNeighborsRegressor(n_neighbors=3)\n",
        "knr.fit(x_train,y_train)\n",
        "y_pred = knr.predict(x_test)\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49.162388451443576"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P77dgms4i-bC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4a3e12b2-24f3-4999-ecc6-5209cafe2c61"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "knr = KNeighborsRegressor(n_neighbors=7)\n",
        "knr.fit(x_train,y_train)\n",
        "y_pred = knr.predict(x_test)\n",
        "mean_squared_error(y_test,y_pred)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50.20116663988429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtPUwS8Ji-oC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "832a5c46-c9b3-4945-e42c-eeea3da69ace"
      },
      "source": [
        "d ={}\n",
        "d_train ={}\n",
        "for i in range(4,12,2):\n",
        "    knr = KNeighborsRegressor(n_neighbors=i)\n",
        "    knr.fit(x_train,y_train)\n",
        "    y_tr = knr.predict(x_train)\n",
        "    d_train[i] = mean_squared_error(y_train,y_tr)\n",
        "    y_pred= knr.predict(x_test)\n",
        "    d[i] = mean_squared_error(y_test,y_pred)\n",
        "d"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 44.80862204724409,\n",
              " 6: 48.25076771653545,\n",
              " 8: 50.09510703740159,\n",
              " 10: 46.7091661417323}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUMVvTpDi-lx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "1bba56fc-721c-4fda-d2d0-784df72a752e"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list(d.keys()),list(d.values()),'b')\n",
        "plt.plot(list(d_train.keys()),list(d_train.values()),'r')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fea141503c8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poaLdi9ci-if",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "32a38fbe-7137-42ab-a29d-0d9e55c61eb5"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "knn = KNeighborsRegressor()\n",
        "grid = GridSearchCV(knn,param_grid={\"n_neighbors\":range(2,10),\"weights\":['uniform','distance']},\\\n",
        "                    scoring=mse,cv=4)\n",
        "grid.fit(x_train,y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-c82e0c26916c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"n_neighbors\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"weights\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mse' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cUyTXU0jP-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c46303dd-2881-4dae-e946-6fc2a05b3ee2"
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "help(make_scorer)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on function make_scorer in module sklearn.metrics._scorer:\n",
            "\n",
            "make_scorer(score_func, greater_is_better=True, needs_proba=False, needs_threshold=False, **kwargs)\n",
            "    Make a scorer from a performance metric or loss function.\n",
            "    \n",
            "    This factory function wraps scoring functions for use in GridSearchCV\n",
            "    and cross_val_score. It takes a score function, such as ``accuracy_score``,\n",
            "    ``mean_squared_error``, ``adjusted_rand_index`` or ``average_precision``\n",
            "    and returns a callable that scores an estimator's output.\n",
            "    \n",
            "    Read more in the :ref:`User Guide <scoring>`.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    score_func : callable,\n",
            "        Score function (or loss function) with signature\n",
            "        ``score_func(y, y_pred, **kwargs)``.\n",
            "    \n",
            "    greater_is_better : boolean, default=True\n",
            "        Whether score_func is a score function (default), meaning high is good,\n",
            "        or a loss function, meaning low is good. In the latter case, the\n",
            "        scorer object will sign-flip the outcome of the score_func.\n",
            "    \n",
            "    needs_proba : boolean, default=False\n",
            "        Whether score_func requires predict_proba to get probability estimates\n",
            "        out of a classifier.\n",
            "    \n",
            "        If True, for binary `y_true`, the score function is supposed to accept\n",
            "        a 1D `y_pred` (i.e., probability of the positive class, shape\n",
            "        `(n_samples,)`).\n",
            "    \n",
            "    needs_threshold : boolean, default=False\n",
            "        Whether score_func takes a continuous decision certainty.\n",
            "        This only works for binary classification using estimators that\n",
            "        have either a decision_function or predict_proba method.\n",
            "    \n",
            "        If True, for binary `y_true`, the score function is supposed to accept\n",
            "        a 1D `y_pred` (i.e., probability of the positive class or the decision\n",
            "        function, shape `(n_samples,)`).\n",
            "    \n",
            "        For example ``average_precision`` or the area under the roc curve\n",
            "        can not be computed using discrete predictions alone.\n",
            "    \n",
            "    **kwargs : additional arguments\n",
            "        Additional parameters to be passed to score_func.\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    scorer : callable\n",
            "        Callable object that returns a scalar score; greater is better.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> from sklearn.metrics import fbeta_score, make_scorer\n",
            "    >>> ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
            "    >>> ftwo_scorer\n",
            "    make_scorer(fbeta_score, beta=2)\n",
            "    >>> from sklearn.model_selection import GridSearchCV\n",
            "    >>> from sklearn.svm import LinearSVC\n",
            "    >>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},\n",
            "    ...                     scoring=ftwo_scorer)\n",
            "    \n",
            "    Notes\n",
            "    -----\n",
            "    If `needs_proba=False` and `needs_threshold=False`, the score\n",
            "    function is supposed to accept the output of :term:`predict`. If\n",
            "    `needs_proba=True`, the score function is supposed to accept the\n",
            "    output of :term:`predict_proba` (For binary `y_true`, the score function is\n",
            "    supposed to accept probability of the positive class). If\n",
            "    `needs_threshold=True`, the score function is supposed to accept the\n",
            "    output of :term:`decision_function`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_cYGNifjQXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse =make_scorer(mean_squared_error,greater_is_better=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qax-wdOhi-YA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "7420c301-9c9c-45f2-9645-8868fe3607f1"
      },
      "source": [
        "grid.best_estimator_"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fb6b380b5a97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwOZ2PBgk2LK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c7c3ea8-f35e-48a7-a33d-34b0dfb79ed8"
      },
      "source": [
        "help(GridSearchCV)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help on class GridSearchCV in module sklearn.model_selection._search:\n",
            "\n",
            "class GridSearchCV(BaseSearchCV)\n",
            " |  Exhaustive search over specified parameter values for an estimator.\n",
            " |  \n",
            " |  Important members are fit, predict.\n",
            " |  \n",
            " |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
            " |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
            " |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
            " |  estimator used.\n",
            " |  \n",
            " |  The parameters of the estimator used to apply these methods are optimized\n",
            " |  by cross-validated grid-search over a parameter grid.\n",
            " |  \n",
            " |  Read more in the :ref:`User Guide <grid_search>`.\n",
            " |  \n",
            " |  Parameters\n",
            " |  ----------\n",
            " |  estimator : estimator object.\n",
            " |      This is assumed to implement the scikit-learn estimator interface.\n",
            " |      Either estimator needs to provide a ``score`` function,\n",
            " |      or ``scoring`` must be passed.\n",
            " |  \n",
            " |  param_grid : dict or list of dictionaries\n",
            " |      Dictionary with parameters names (string) as keys and lists of\n",
            " |      parameter settings to try as values, or a list of such\n",
            " |      dictionaries, in which case the grids spanned by each dictionary\n",
            " |      in the list are explored. This enables searching over any sequence\n",
            " |      of parameter settings.\n",
            " |  \n",
            " |  scoring : string, callable, list/tuple, dict or None, default: None\n",
            " |      A single string (see :ref:`scoring_parameter`) or a callable\n",
            " |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
            " |  \n",
            " |      For evaluating multiple metrics, either give a list of (unique) strings\n",
            " |      or a dict with names as keys and callables as values.\n",
            " |  \n",
            " |      NOTE that when using custom scorers, each scorer should return a single\n",
            " |      value. Metric functions returning a list/array of values can be wrapped\n",
            " |      into multiple scorers that return one value each.\n",
            " |  \n",
            " |      See :ref:`multimetric_grid_search` for an example.\n",
            " |  \n",
            " |      If None, the estimator's score method is used.\n",
            " |  \n",
            " |  n_jobs : int or None, optional (default=None)\n",
            " |      Number of jobs to run in parallel.\n",
            " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
            " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
            " |      for more details.\n",
            " |  \n",
            " |  pre_dispatch : int, or string, optional\n",
            " |      Controls the number of jobs that get dispatched during parallel\n",
            " |      execution. Reducing this number can be useful to avoid an\n",
            " |      explosion of memory consumption when more jobs get dispatched\n",
            " |      than CPUs can process. This parameter can be:\n",
            " |  \n",
            " |          - None, in which case all the jobs are immediately\n",
            " |            created and spawned. Use this for lightweight and\n",
            " |            fast-running jobs, to avoid delays due to on-demand\n",
            " |            spawning of the jobs\n",
            " |  \n",
            " |          - An int, giving the exact number of total jobs that are\n",
            " |            spawned\n",
            " |  \n",
            " |          - A string, giving an expression as a function of n_jobs,\n",
            " |            as in '2*n_jobs'\n",
            " |  \n",
            " |  iid : boolean, default=False\n",
            " |      If True, return the average score across folds, weighted by the number\n",
            " |      of samples in each test set. In this case, the data is assumed to be\n",
            " |      identically distributed across the folds, and the loss minimized is\n",
            " |      the total loss per sample, and not the mean loss across the folds.\n",
            " |  \n",
            " |      .. deprecated:: 0.22\n",
            " |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
            " |  \n",
            " |  cv : int, cross-validation generator or an iterable, optional\n",
            " |      Determines the cross-validation splitting strategy.\n",
            " |      Possible inputs for cv are:\n",
            " |  \n",
            " |      - None, to use the default 5-fold cross validation,\n",
            " |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
            " |      - :term:`CV splitter`,\n",
            " |      - An iterable yielding (train, test) splits as arrays of indices.\n",
            " |  \n",
            " |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
            " |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
            " |      other cases, :class:`KFold` is used.\n",
            " |  \n",
            " |      Refer :ref:`User Guide <cross_validation>` for the various\n",
            " |      cross-validation strategies that can be used here.\n",
            " |  \n",
            " |      .. versionchanged:: 0.22\n",
            " |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
            " |  \n",
            " |  refit : boolean, string, or callable, default=True\n",
            " |      Refit an estimator using the best found parameters on the whole\n",
            " |      dataset.\n",
            " |  \n",
            " |      For multiple metric evaluation, this needs to be a string denoting the\n",
            " |      scorer that would be used to find the best parameters for refitting\n",
            " |      the estimator at the end.\n",
            " |  \n",
            " |      Where there are considerations other than maximum score in\n",
            " |      choosing a best estimator, ``refit`` can be set to a function which\n",
            " |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
            " |      case, the ``best_estimator_`` and ``best_parameters_`` will be set\n",
            " |      according to the returned ``best_index_`` while the ``best_score_``\n",
            " |      attribute will not be available.\n",
            " |  \n",
            " |      The refitted estimator is made available at the ``best_estimator_``\n",
            " |      attribute and permits using ``predict`` directly on this\n",
            " |      ``GridSearchCV`` instance.\n",
            " |  \n",
            " |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
            " |      ``best_score_`` and ``best_params_`` will only be available if\n",
            " |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
            " |      scorer.\n",
            " |  \n",
            " |      See ``scoring`` parameter to know more about multiple metric\n",
            " |      evaluation.\n",
            " |  \n",
            " |      .. versionchanged:: 0.20\n",
            " |          Support for callable added.\n",
            " |  \n",
            " |  verbose : integer\n",
            " |      Controls the verbosity: the higher, the more messages.\n",
            " |  \n",
            " |  error_score : 'raise' or numeric\n",
            " |      Value to assign to the score if an error occurs in estimator fitting.\n",
            " |      If set to 'raise', the error is raised. If a numeric value is given,\n",
            " |      FitFailedWarning is raised. This parameter does not affect the refit\n",
            " |      step, which will always raise the error. Default is ``np.nan``.\n",
            " |  \n",
            " |  return_train_score : boolean, default=False\n",
            " |      If ``False``, the ``cv_results_`` attribute will not include training\n",
            " |      scores.\n",
            " |      Computing training scores is used to get insights on how different\n",
            " |      parameter settings impact the overfitting/underfitting trade-off.\n",
            " |      However computing the scores on the training set can be computationally\n",
            " |      expensive and is not strictly required to select the parameters that\n",
            " |      yield the best generalization performance.\n",
            " |  \n",
            " |  \n",
            " |  Examples\n",
            " |  --------\n",
            " |  >>> from sklearn import svm, datasets\n",
            " |  >>> from sklearn.model_selection import GridSearchCV\n",
            " |  >>> iris = datasets.load_iris()\n",
            " |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
            " |  >>> svc = svm.SVC()\n",
            " |  >>> clf = GridSearchCV(svc, parameters)\n",
            " |  >>> clf.fit(iris.data, iris.target)\n",
            " |  GridSearchCV(estimator=SVC(),\n",
            " |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
            " |  >>> sorted(clf.cv_results_.keys())\n",
            " |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
            " |   'param_C', 'param_kernel', 'params',...\n",
            " |   'rank_test_score', 'split0_test_score',...\n",
            " |   'split2_test_score', ...\n",
            " |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
            " |  \n",
            " |  Attributes\n",
            " |  ----------\n",
            " |  cv_results_ : dict of numpy (masked) ndarrays\n",
            " |      A dict with keys as column headers and values as columns, that can be\n",
            " |      imported into a pandas ``DataFrame``.\n",
            " |  \n",
            " |      For instance the below given table\n",
            " |  \n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
            " |      +============+===========+============+=================+===+=========+\n",
            " |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
            " |      +------------+-----------+------------+-----------------+---+---------+\n",
            " |  \n",
            " |      will be represented by a ``cv_results_`` dict of::\n",
            " |  \n",
            " |          {\n",
            " |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
            " |                                       mask = [False False False False]...)\n",
            " |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
            " |                                      mask = [ True  True False False]...),\n",
            " |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
            " |                                       mask = [False False  True  True]...),\n",
            " |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
            " |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
            " |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
            " |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
            " |          'rank_test_score'    : [2, 4, 3, 1],\n",
            " |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
            " |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
            " |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
            " |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
            " |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
            " |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
            " |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
            " |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
            " |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
            " |          }\n",
            " |  \n",
            " |      NOTE\n",
            " |  \n",
            " |      The key ``'params'`` is used to store a list of parameter\n",
            " |      settings dicts for all the parameter candidates.\n",
            " |  \n",
            " |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
            " |      ``std_score_time`` are all in seconds.\n",
            " |  \n",
            " |      For multi-metric evaluation, the scores for all the scorers are\n",
            " |      available in the ``cv_results_`` dict at the keys ending with that\n",
            " |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
            " |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
            " |  \n",
            " |  best_estimator_ : estimator\n",
            " |      Estimator that was chosen by the search, i.e. estimator\n",
            " |      which gave highest score (or smallest loss if specified)\n",
            " |      on the left out data. Not available if ``refit=False``.\n",
            " |  \n",
            " |      See ``refit`` parameter for more information on allowed values.\n",
            " |  \n",
            " |  best_score_ : float\n",
            " |      Mean cross-validated score of the best_estimator\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |      This attribute is not available if ``refit`` is a function.\n",
            " |  \n",
            " |  best_params_ : dict\n",
            " |      Parameter setting that gave the best results on the hold out data.\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  best_index_ : int\n",
            " |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
            " |      candidate parameter setting.\n",
            " |  \n",
            " |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
            " |      the parameter setting for the best model, that gives the highest\n",
            " |      mean score (``search.best_score_``).\n",
            " |  \n",
            " |      For multi-metric evaluation, this is present only if ``refit`` is\n",
            " |      specified.\n",
            " |  \n",
            " |  scorer_ : function or a dict\n",
            " |      Scorer function used on the held out data to choose the best\n",
            " |      parameters for the model.\n",
            " |  \n",
            " |      For multi-metric evaluation, this attribute holds the validated\n",
            " |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
            " |  \n",
            " |  n_splits_ : int\n",
            " |      The number of cross-validation splits (folds/iterations).\n",
            " |  \n",
            " |  refit_time_ : float\n",
            " |      Seconds used for refitting the best model on the whole dataset.\n",
            " |  \n",
            " |      This is present only if ``refit`` is not False.\n",
            " |  \n",
            " |  Notes\n",
            " |  -----\n",
            " |  The parameters selected are those that maximize the score of the left out\n",
            " |  data, unless an explicit score is passed in which case it is used instead.\n",
            " |  \n",
            " |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
            " |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
            " |  reasons if individual jobs take very little time, but may raise errors if\n",
            " |  the dataset is large and not enough memory is available.  A workaround in\n",
            " |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
            " |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
            " |  n_jobs`.\n",
            " |  \n",
            " |  See Also\n",
            " |  ---------\n",
            " |  :class:`ParameterGrid`:\n",
            " |      generates all the combinations of a hyperparameter grid.\n",
            " |  \n",
            " |  :func:`sklearn.model_selection.train_test_split`:\n",
            " |      utility function to split the data into a development set usable\n",
            " |      for fitting a GridSearchCV instance and an evaluation set for\n",
            " |      its final evaluation.\n",
            " |  \n",
            " |  :func:`sklearn.metrics.make_scorer`:\n",
            " |      Make a scorer from a performance metric or loss function.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      GridSearchCV\n",
            " |      BaseSearchCV\n",
            " |      sklearn.base.MetaEstimatorMixin\n",
            " |      sklearn.base.BaseEstimator\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, estimator, param_grid, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from BaseSearchCV:\n",
            " |  \n",
            " |  decision_function(self, X)\n",
            " |      Call decision_function on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``decision_function``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  fit(self, X, y=None, groups=None, **fit_params)\n",
            " |      Run fit with all sets of parameters.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      \n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Training vector, where n_samples is the number of samples and\n",
            " |          n_features is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output) or (n_samples,), optional\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      groups : array-like, with shape (n_samples,), optional\n",
            " |          Group labels for the samples used while splitting the dataset into\n",
            " |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
            " |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
            " |      \n",
            " |      **fit_params : dict of string -> object\n",
            " |          Parameters passed to the ``fit`` method of the estimator\n",
            " |  \n",
            " |  inverse_transform(self, Xt)\n",
            " |      Call inverse_transform on the estimator with the best found params.\n",
            " |      \n",
            " |      Only available if the underlying estimator implements\n",
            " |      ``inverse_transform`` and ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      Xt : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  predict(self, X)\n",
            " |      Call predict on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  predict_log_proba(self, X)\n",
            " |      Call predict_log_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_log_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  predict_proba(self, X)\n",
            " |      Call predict_proba on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if ``refit=True`` and the underlying estimator supports\n",
            " |      ``predict_proba``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  score(self, X, y=None)\n",
            " |      Returns the score on the given data, if the estimator has been refit.\n",
            " |      \n",
            " |      This uses the score defined by ``scoring`` where provided, and the\n",
            " |      ``best_estimator_.score`` method otherwise.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : array-like of shape (n_samples, n_features)\n",
            " |          Input data, where n_samples is the number of samples and\n",
            " |          n_features is the number of features.\n",
            " |      \n",
            " |      y : array-like of shape (n_samples, n_output) or (n_samples,), optional\n",
            " |          Target relative to X for classification or regression;\n",
            " |          None for unsupervised learning.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      score : float\n",
            " |  \n",
            " |  transform(self, X)\n",
            " |      Call transform on the estimator with the best found parameters.\n",
            " |      \n",
            " |      Only available if the underlying estimator supports ``transform`` and\n",
            " |      ``refit=True``.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      X : indexable, length n_samples\n",
            " |          Must fulfill the input assumptions of the\n",
            " |          underlying estimator.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from BaseSearchCV:\n",
            " |  \n",
            " |  classes_\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from sklearn.base.BaseEstimator:\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __repr__(self, N_CHAR_MAX=700)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  get_params(self, deep=True)\n",
            " |      Get parameters for this estimator.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      deep : bool, default=True\n",
            " |          If True, will return the parameters for this estimator and\n",
            " |          contained subobjects that are estimators.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      params : mapping of string to any\n",
            " |          Parameter names mapped to their values.\n",
            " |  \n",
            " |  set_params(self, **params)\n",
            " |      Set the parameters of this estimator.\n",
            " |      \n",
            " |      The method works on simple estimators as well as on nested objects\n",
            " |      (such as pipelines). The latter have parameters of the form\n",
            " |      ``<component>__<parameter>`` so that it's possible to update each\n",
            " |      component of a nested object.\n",
            " |      \n",
            " |      Parameters\n",
            " |      ----------\n",
            " |      **params : dict\n",
            " |          Estimator parameters.\n",
            " |      \n",
            " |      Returns\n",
            " |      -------\n",
            " |      self : object\n",
            " |          Estimator instance.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_-3fO-Jk2cW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "93b60d0e-9d78-4cc1-8d6f-826a4d5aa36f"
      },
      "source": [
        "y_pred = grid.predict(x_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-f62f1cc154a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'grid' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViQ5E0c1k2X6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "55543c03-96bc-4e18-9156-dd0b58fa07e9"
      },
      "source": [
        "mean_squared_error(y_pred,y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.7091661417323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnxJprl-l8CT",
        "colab_type": "text"
      },
      "source": [
        "**Pipeline**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cglxp2del6j7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "2654e39e-a0f9-4509-9c75-1fc918373362"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "estimators = [(\"scaler\",MinMaxScaler()),(\"knn\",KNeighborsRegressor())]\n",
        "pipe = Pipeline(estimators)\n",
        "pipe.fit(x_train,y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('scaler', MinMaxScaler(copy=True, feature_range=(0, 1))),\n",
              "                ('knn',\n",
              "                 KNeighborsRegressor(algorithm='auto', leaf_size=30,\n",
              "                                     metric='minkowski', metric_params=None,\n",
              "                                     n_jobs=None, n_neighbors=5, p=2,\n",
              "                                     weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI_TcV_ql6x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = pipe.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQrlJn-tl622",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b81d1b8f-6b4a-46ec-e0bd-6f58c9743d17"
      },
      "source": [
        "mean_squared_error(y_pred,y_test)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16.733691338582673"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}